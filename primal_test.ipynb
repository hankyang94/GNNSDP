{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import torch_geometric.nn as pyg_nn \n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "import torch.optim as optim\n",
    "import os.path as osp\n",
    "import scipy.io as sio\n",
    "from dataset import QUASARDataset\n",
    "from primal_model import PrimalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data graph type: 1.\n",
      "Data graph type: 1.\n",
      "Data graph type: 1.\n",
      "Data graph type: 1.\n"
     ]
    }
   ],
   "source": [
    "dir = '/home/hank/Datasets/QUASAR/small'\n",
    "dataset = QUASARDataset(dir,num_graphs=100,remove_self_loops=True)\n",
    "test_dir = '/home/hank/Datasets/QUASAR/small-test'\n",
    "testset = QUASARDataset(test_dir,num_graphs=100,remove_self_loops=True)\n",
    "test_dir_30 = '/home/hank/Datasets/QUASAR/N30-100'\n",
    "testset_30 = QUASARDataset(test_dir_30,num_graphs=100,remove_self_loops=True)\n",
    "large_dir = '/home/hank/Datasets/QUASAR/N30-1000'\n",
    "largeset = QUASARDataset(large_dir,num_graphs=1000,remove_self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: node_feature_mode = 1, mp_input_dim = 6, relu_slope = 0.1. GNN type: SAGE. Residual: True. BatchNorm: False. Factor: False. Resmode: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PrimalModel(\n",
       "  (mp_convs): ModuleList(\n",
       "    (0): SAGEConv(6, 64)\n",
       "    (1): SAGEConv(64, 64)\n",
       "    (2): SAGEConv(64, 64)\n",
       "    (3): SAGEConv(64, 64)\n",
       "    (4): SAGEConv(64, 64)\n",
       "    (5): SAGEConv(64, 64)\n",
       "    (6): SAGEConv(64, 64)\n",
       "    (7): SAGEConv(64, 64)\n",
       "  )\n",
       "  (primal_node_mlp): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       "  (primal_edge_mlp): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNN_TYPE = 'SAGE'\n",
    "GNN_HIDDEN_DIM = 64\n",
    "GNN_OUT_DIM = 64\n",
    "GNN_LAYER = 6\n",
    "NODE_MODE = 1\n",
    "DATA_GRAPH_TYPE = 1\n",
    "DROPOUT = 0\n",
    "MLP_LAYER = 2\n",
    "RESMODE = 2 # 1: before activation, 2: after activation\n",
    "FACTOR = False\n",
    "model   = PrimalModel(node_feature_mode=NODE_MODE,\n",
    "                     gnn_type=GNN_TYPE,\n",
    "                     mp_hidden_dim=GNN_HIDDEN_DIM,mp_output_dim=GNN_OUT_DIM,mp_num_layers=GNN_LAYER, \n",
    "                     primal_node_mlp_hidden_dim=GNN_HIDDEN_DIM,primal_node_mlp_output_dim=10,\n",
    "                     node_mlp_num_layers=MLP_LAYER,\n",
    "                     primal_edge_mlp_hidden_dim=GNN_HIDDEN_DIM,primal_edge_mlp_output_dim=10,\n",
    "                     edge_mlp_num_layers=MLP_LAYER, \n",
    "                     dropout_rate=DROPOUT,\n",
    "                     relu_slope=0.1,\n",
    "                     residual=True,\n",
    "                     resmode=RESMODE,\n",
    "                     factor=FACTOR)\n",
    "# model.load_state_dict(torch.load('./models/primal_model_SAGE_4_64_64_1_1_1000_0.0_2.pth'))\n",
    "# model.load_state_dict(torch.load('./models/primal_model_N30-1000_SAGE_3_True_False_factor_True.pth'))\n",
    "model.load_state_dict(torch.load('./models/primal_model_N30-1000_SAGE_6_True_False_399.pth'))\n",
    "model.double()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hank/miniconda3/envs/gnnsdp/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.2656.\n"
     ]
    }
   ],
   "source": [
    "# results on large train set\n",
    "loader = DataLoader(largeset,batch_size=1,shuffle=True)\n",
    "train_loss = []\n",
    "for batch in loader:\n",
    "    _, X = model(batch)\n",
    "    primal_loss = model.loss(batch,X)\n",
    "    train_loss.append(primal_loss.item())\n",
    "train_acc = torch.mean(torch.tensor(train_loss))\n",
    "print('Train acc: {:.4f}.'.format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7535.\n"
     ]
    }
   ],
   "source": [
    "# results on train set\n",
    "loader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "train_loss = []\n",
    "for batch in loader:\n",
    "    _, X = model(batch)\n",
    "    primal_loss = model.loss(batch,X)\n",
    "    # print('batch loss: {:.4f}.'.format(\n",
    "    #             primal_loss.item()))\n",
    "    train_loss.append(primal_loss.item())\n",
    "train_acc = torch.mean(torch.tensor(train_loss))\n",
    "print('Train acc: {:.4f}.'.format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7515.\n"
     ]
    }
   ],
   "source": [
    "# results on test set\n",
    "loader = DataLoader(testset,batch_size=1,shuffle=True)\n",
    "test_loss = []\n",
    "for batch in loader:\n",
    "    _, X = model(batch)\n",
    "    primal_loss = model.loss(batch,X)\n",
    "    test_loss.append(primal_loss.item())\n",
    "test_acc = torch.mean(torch.tensor(test_loss))\n",
    "print('Train acc: {:.4f}.'.format(test_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.7141.\n"
     ]
    }
   ],
   "source": [
    "# results on test set N=30\n",
    "loader = DataLoader(testset_30,batch_size=1,shuffle=True)\n",
    "test_loss = []\n",
    "for batch in loader:\n",
    "    _, X = model(batch)\n",
    "    primal_loss = model.loss(batch,X)\n",
    "    test_loss.append(primal_loss.item())\n",
    "test_acc = torch.mean(torch.tensor(test_loss))\n",
    "print('Test acc: {:.4f}.'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: node_feature_mode = 1, mp_input_dim = 6, relu_slope = 0.1. GNN type: SAGE. Residual: True. BatchNorm: False. Factor: True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hank/miniconda3/envs/gnnsdp/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.1590.\n",
      "Test acc: 0.9947.\n"
     ]
    }
   ],
   "source": [
    "# Factor model\n",
    "GNN_TYPE = 'SAGE'\n",
    "GNN_HIDDEN_DIM = 64\n",
    "GNN_OUT_DIM = 64\n",
    "GNN_LAYER = 1\n",
    "NODE_MODE = 1\n",
    "DATA_GRAPH_TYPE = 1\n",
    "NUM_EPOCHES = 500\n",
    "DROPOUT = 0.0\n",
    "MLP_LAYER = 1\n",
    "RESIDUAL = True\n",
    "BATCHNORM = False\n",
    "FACTOR = True\n",
    "model   = PrimalModel(node_feature_mode=NODE_MODE,\n",
    "                    gnn_type=GNN_TYPE,\n",
    "                    mp_hidden_dim=GNN_HIDDEN_DIM,mp_output_dim=GNN_OUT_DIM,mp_num_layers=GNN_LAYER, \n",
    "                    primal_node_mlp_hidden_dim=GNN_OUT_DIM,primal_node_mlp_output_dim=10,\n",
    "                    node_mlp_num_layers=MLP_LAYER,\n",
    "                    primal_edge_mlp_hidden_dim=GNN_OUT_DIM,primal_edge_mlp_output_dim=10,\n",
    "                    edge_mlp_num_layers=MLP_LAYER,\n",
    "                    dropout_rate=DROPOUT,\n",
    "                    relu_slope=0.1,\n",
    "                    residual=RESIDUAL,\n",
    "                    batchnorm=BATCHNORM,\n",
    "                    factor=FACTOR)\n",
    "model.double()\n",
    "model.load_state_dict(torch.load('./models/primal_model_small_SAGE_1_True_False_factor_True.pth'))\n",
    "model.eval()\n",
    "# train\n",
    "loader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "train_loss = []\n",
    "for batch in loader:\n",
    "    _, X = model(batch)\n",
    "    primal_loss = model.loss(batch,X)\n",
    "    train_loss.append(primal_loss.item())\n",
    "train_acc = torch.mean(torch.tensor(train_loss))\n",
    "print('Train acc: {:.4f}.'.format(train_acc))\n",
    "# test\n",
    "loader = DataLoader(testset,batch_size=1,shuffle=True)\n",
    "test_loss = []\n",
    "for batch in loader:\n",
    "    _, X = model(batch)\n",
    "    primal_loss = model.loss(batch,X)\n",
    "    test_loss.append(primal_loss.item())\n",
    "test_acc = torch.mean(torch.tensor(test_loss))\n",
    "print('Test acc: {:.4f}.'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0050, -0.0026,  0.0176,  ..., -0.0080, -0.0066,  0.0586],\n",
      "        [-0.0026,  0.0014, -0.0092,  ...,  0.0042,  0.0034, -0.0305],\n",
      "        [ 0.0176, -0.0092,  0.0614,  ..., -0.0280, -0.0230,  0.2043],\n",
      "        ...,\n",
      "        [-0.0080,  0.0042, -0.0280,  ...,  0.0128,  0.0105, -0.0934],\n",
      "        [-0.0066,  0.0034, -0.0230,  ...,  0.0105,  0.0086, -0.0765],\n",
      "        [ 0.0586, -0.0305,  0.2043,  ..., -0.0934, -0.0765,  0.6800]],\n",
      "       dtype=torch.float64, grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: node_feature_mode = 1, mp_input_dim = 6, relu_slope = 0.1. GNN type: SAGE.\n",
      "Rand train acc: 1.0471.\n",
      "Rand test acc: 1.0403.\n"
     ]
    }
   ],
   "source": [
    "# results of randmodel\n",
    "randmodel = PrimalModel(node_feature_mode=NODE_MODE,\n",
    "                     gnn_type=GNN_TYPE,\n",
    "                     mp_hidden_dim=GNN_HIDDEN_DIM,mp_output_dim=GNN_OUT_DIM,mp_num_layers=GNN_LAYER, \n",
    "                     primal_node_mlp_hidden_dim=GNN_HIDDEN_DIM,primal_node_mlp_output_dim=10,\n",
    "                     node_mlp_num_layers=MLP_LAYER,\n",
    "                     primal_edge_mlp_hidden_dim=GNN_HIDDEN_DIM,primal_edge_mlp_output_dim=10,\n",
    "                     edge_mlp_num_layers=MLP_LAYER, \n",
    "                     dropout_rate=DROPOUT,\n",
    "                     relu_slope=0.1)\n",
    "randmodel.double()\n",
    "randmodel.eval()\n",
    "\n",
    "loader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "train_loss = []\n",
    "for batch in loader:\n",
    "    _, X = randmodel(batch)\n",
    "    primal_loss = randmodel.loss(batch,X)\n",
    "    train_loss.append(primal_loss.item())\n",
    "train_acc = torch.mean(torch.tensor(train_loss))\n",
    "print('Rand train acc: {:.4f}.'.format(train_acc))\n",
    "\n",
    "loader = DataLoader(testset,batch_size=1,shuffle=True)\n",
    "test_loss = []\n",
    "for batch in loader:\n",
    "    _, X = randmodel(batch)\n",
    "    primal_loss = randmodel.loss(batch,X)\n",
    "    test_loss.append(primal_loss.item())\n",
    "test_acc = torch.mean(torch.tensor(test_loss))\n",
    "print('Rand test acc: {:.4f}.'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6548f5818eb0d21304c8b75b8d24fe6a88bc84b221a3961d704ebd009d182722"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gnnsdp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
